{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQVjOczgND0o"
   },
   "source": [
    "# Projet de Cloud Computing\n",
    "\n",
    "Génération des charges de travail pour les FaaS dans les grandes plateformes cloud : Cas de Microsoft Azure\n",
    "\n",
    "Membres du groupe :\n",
    "- ATANGANA Julien Patrick\n",
    "- MARIA-MBOMO MBOA Marilyn\n",
    "- MELIE DOUMTSOP Godsend\n",
    "- NGUEN Kevina Anne\n",
    "- TALLA CHENDJOU James\n",
    "\n",
    "Sous la supervision de Pr Alain TCHANA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uW8dDaYSE5OY"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3IDugFSE8Ce"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqhfXm7JiklJ",
    "outputId": "011a36e6-3812-4716-db2f-136df1fbd563"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import namedtuple\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Lp68qFj8nhb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import NamedTuple\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g24I8GXapg6j"
   },
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-fiz4nKpj6S",
    "outputId": "4aa40b83-b60d-4b17-9994-a069e2d59835"
   },
   "outputs": [],
   "source": [
    "!wget https://azurecloudpublicdataset2.blob.core.windows.net/azurepublicdatasetv2/azurefunctions_dataset2019/azurefunctions-dataset2019.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVPa3YCnptaK",
    "outputId": "ddd78963-f2ef-44fa-8d59-f44bd955abed"
   },
   "outputs": [],
   "source": [
    "!tar xvf azurefunctions-dataset2019.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6Nvw60xOQAe"
   },
   "source": [
    "# Path To Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1XN-fdQQWzL"
   },
   "outputs": [],
   "source": [
    "path_to_dataset_folder = \"/content/\"\n",
    "data_path =\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlsX8tvZvqNx"
   },
   "source": [
    "# Arrival model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlA0114hKI8V"
   },
   "source": [
    "# Arranging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gA-rnVbnWnzW",
    "outputId": "e0fcd919-57dd-474d-99c8-3a6e3db3bc1c"
   },
   "outputs": [],
   "source": [
    "functions = []\n",
    "apps = []\n",
    "owners = []\n",
    "number_invocations = []\n",
    "X_data = []\n",
    "y_data = []\n",
    "hash_functions = []\n",
    "\n",
    "for day in range(1, 3):\n",
    "  inv_df_d = pd.read_csv(path_to_dataset_folder + 'invocations_per_function_md.anon.d0'+ str(day) +'.csv') if day < 10 else pd.read_csv(path_to_dataset_folder + 'invocations_per_function_md.anon.d'+ str(day) +'.csv')\n",
    "  \n",
    "  hash_functions.extend(inv_df_d['HashFunction'].unique().tolist())\n",
    "\n",
    "  for minute in range(1, 1441):\n",
    "    hashes = inv_df_d.loc[inv_df_d[str(minute)] > 0, ['HashOwner', 'HashApp', 'HashFunction']]\n",
    "    x_data = [0]*1452\n",
    "    x_data[minute-1] = 1\n",
    "    x_data[1440:1440+day] = [1]*day\n",
    "    X_data.append(x_data)\n",
    "\n",
    "    app_func = hashes.groupby('HashApp')\n",
    "    hash_apps = hashes['HashApp'].unique().tolist()\n",
    "    hash_apps_size = len(hash_apps)\n",
    "    functions.append(',|,'.join(map(str, app_func['HashFunction'].transform(lambda x: ','.join(map(str, x))).unique().tolist())) + ',|')\n",
    "\n",
    "    if minute == 1:\n",
    "      print(functions)\n",
    "\n",
    "    apps.append(','.join(map(str, hash_apps)))\n",
    "    y_data.append(hash_apps_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RC9cOBdsep5"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X_data, columns=[str(i) for i in range(1, 1453)])\n",
    "data['HashFunction'] = functions\n",
    "data['HashApps'] = apps\n",
    "data['number_of_apps'] = y_data\n",
    "data.to_csv(data_path + 'data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfgmQyv34hQu",
    "outputId": "639511f0-9b44-407a-8021-8864e5edc1b1"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEeIHhkMU7I5"
   },
   "outputs": [],
   "source": [
    "hash_functions = list(set(hash_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBAo3cfTW2vI",
    "outputId": "fa6eea7e-9288-4a52-cca4-4a04e41b0dd2"
   },
   "outputs": [],
   "source": [
    "len(hash_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYTzbdXfgdEB"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glIuRvQENZ7j"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path + 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "sCABEPGHgquu",
    "outputId": "f169f850-c11a-4b57-c7fe-a7e6eceeee11"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "lT_jIhpZhh-k",
    "outputId": "ac66b205-666a-489f-e881-764f214a4401"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxScwiEAu7BV",
    "outputId": "b6ae22b0-6955-4257-ba31-cfa73a94ed72"
   },
   "outputs": [],
   "source": [
    "data['HashFunction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zn-XGvknhr0o",
    "outputId": "b8dc4e44-514a-46d3-8e6d-1eb5092251ad"
   },
   "outputs": [],
   "source": [
    "data['HashApps'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIaIpLDBiPsu"
   },
   "outputs": [],
   "source": [
    "DAYS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RvpRNFhgwFW"
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, [str(i) for i in range(1, 1441+DAYS)]]    # for 12 days - 1452\n",
    "y = data['number_of_apps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osZKQ5dio7hk"
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = X.astype('float64')\n",
    "y = y.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96TgIcxOiU4U",
    "outputId": "5b7daed7-fc83-4c7a-d732-149afc44dc0b"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIC3lOEniZfB",
    "outputId": "3b5b83ec-147f-43ff-a782-e6229495008f"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hWr6Ke6gvzr"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YC0R0apotXK",
    "outputId": "68538ced-bd51-4bbd-a541-a083591f7159"
   },
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzE5bx7Ugund",
    "outputId": "cc86f9dc-9481-4363-db91-175ba97f815b"
   },
   "outputs": [],
   "source": [
    "poisson_fit = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit_regularized(alpha=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiwgEw5Zjwvm"
   },
   "outputs": [],
   "source": [
    "poisson_fit.save(data_path + 'arr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DpAOF-Ljwsx"
   },
   "outputs": [],
   "source": [
    "def get_quantiles(predict_arr, args):\n",
    "    \"\"\"Get prediction quantiles.\"\"\"\n",
    "    all_means = np.repeat(predict_arr, args.npoisson_samps,\n",
    "                          axis=0).astype(np.float64)\n",
    "    psamps = np.random.poisson(all_means)\n",
    "    p95 = np.percentile(psamps, 95, axis=0)\n",
    "    p50 = np.percentile(psamps, 50, axis=0)\n",
    "    p05 = np.percentile(psamps, 5, axis=0)\n",
    "    return p05, p50, p95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgoaImnwlGym",
    "outputId": "821bef53-a288-4564-b555-72cc89865438"
   },
   "outputs": [],
   "source": [
    "X_test[7][1441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfYFQGGMjwp-"
   },
   "outputs": [],
   "source": [
    "pred = poisson_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdI0c4lojwnD"
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiSTLUm3v8mW"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf58VEvNo0g4"
   },
   "outputs": [],
   "source": [
    "m = data.loc[0, [str(i) for i in range(1, 1447)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWM_AwIipQlE"
   },
   "outputs": [],
   "source": [
    "m[[str(i) for i in range(1, 144)]].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwf1ZgSM4VgB"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90cN0c6tHY5L"
   },
   "outputs": [],
   "source": [
    "BOUND = \"|\"\n",
    "IGNORE_INDEX = -100\n",
    "ITEM_DATA_SEP = ','\n",
    "TRACE_DATA_SEP = \" \"\n",
    "DAYS = 2\n",
    "\n",
    "\n",
    "class ExampleKeys(Enum):\n",
    "    \"\"\"Keys we can use to extract values from an example.\"\"\"\n",
    "    INPUT = \"input\"\n",
    "    TARGET = \"target\"\n",
    "    OUT_MASK = \"mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLeB6EITSBkR"
   },
   "outputs": [],
   "source": [
    "hash_functions.append('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSs18ljBPqUF"
   },
   "outputs": [],
   "source": [
    "class FlavTensorMaker():\n",
    "    \"\"\"Make tensors for inputs and outputs, as requested, given flavor\n",
    "    map, which is used only to get list of flavors, which we turn into\n",
    "    a mapping from flavors to indexes in the features tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hash_functs):    # vector containing hashes of functions \n",
    "        \"\"\"The tensors depend on how many codes in the flav_map.\n",
    "        Args:\n",
    "        flav_map_fn: String, filename with map from flavors to their codes.\n",
    "        range_start/stop: Int: timestamps for start/end of training data.\n",
    "        range_idx: Int: If given, tensor maker will use this index in\n",
    "        the range features (modulo the number of range features).\n",
    "        \"\"\"\n",
    "        self.flav_idxs, self.idx_flavs = self.get_flav_idxs(hash_functs)\n",
    "        self.ninput = len(self.flav_idxs)\n",
    "        # For timestamp feats:\n",
    "        self.ninput += 1440  + DAYS\n",
    "        self.noutput = len(self.flav_idxs)\n",
    "    \n",
    "\n",
    "    def get_ninput(self):\n",
    "        \"\"\"Getter for the ninput\n",
    "        \"\"\"\n",
    "        return self.ninput\n",
    "\n",
    "    def get_noutput(self):\n",
    "        \"\"\"Getter for the noutput\n",
    "        \"\"\"\n",
    "        return self.noutput\n",
    "\n",
    "    @staticmethod\n",
    "    def get_flav_idxs(hash_functs):\n",
    "        \"\"\"Return map from flavor to index, and one with reverse mapping,\n",
    "        using values in flavstr_map.\n",
    "        \"\"\"\n",
    "        func_idx = {}\n",
    "        idx_func = {}\n",
    "        # hash_func.append('|')\n",
    "\n",
    "        for idx, hash_f in enumerate(hash_functs):\n",
    "            func_idx[hash_f] = idx\n",
    "            idx_func[idx] = hash_f\n",
    "    \n",
    "        return func_idx, idx_func\n",
    "\n",
    "    def __one_hot_flav_line(self, hash_func):\n",
    "        \"\"\"One-hot-encode line of flavs as a tensor of LEN(LINE) x 1 x NDIMS.\n",
    "        \"\"\"\n",
    "        ndims = len(self.flav_idxs)\n",
    "        fvals = torch.tensor([self.flav_idxs[f] for f in hash_func])\n",
    "        tensor = torch.nn.functional.one_hot(fvals,\n",
    "                                             num_classes=ndims) \\\n",
    "                                    .unsqueeze(dim=1)\n",
    "        return tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def one_hots_timestamp(minute_day):\n",
    "        \"\"\"Encode both hour-of-day (from 1 to 24) and day-of-week (from 1 to\n",
    "        7) using 1-hot ecoding and return 31-dimensional tensor.\n",
    "        This is public so we can re-use it in other classes\n",
    "        (e.g. features for Poisson Regression in narrivals).\n",
    "        \"\"\"\n",
    "        # We don't know what REAL day it was, but even if back at\n",
    "        # start of Linux, it's fine for finding patterns:\n",
    "        \n",
    "        tensor = torch.from_numpy(np.array(minute_day))\n",
    "        return tensor\n",
    "\n",
    "\n",
    "    def encode_input(self, minute_day, line):\n",
    "        \"\"\"Given line of NFLAVS, output should be (NFLAVS-1) x 1 x NFEATURES\n",
    "        [since last flav is not part of INPUT].\n",
    "        \"\"\"\n",
    "        input_line = line[:-1]\n",
    "        print(input_line)\n",
    "        oneh_flavs = self.__one_hot_flav_line(input_line)\n",
    "        # timestamp/range encoded once, then tiled:\n",
    "        oneh_ts = self.one_hots_timestamp(minute_day)\n",
    "        oneh_ts_line = oneh_ts.repeat(len(input_line), 1, 1)\n",
    "        \n",
    "        return torch.cat([oneh_flavs, oneh_ts_line], dim=2)\n",
    "\n",
    "    def encode_target(self, hash_func):\n",
    "        \"\"\"For line of NFLAVS, return NFLAVS-1 targets giving indexes of the\n",
    "        true flavs.\n",
    "        \"\"\"\n",
    "        flav_idxs = [self.flav_idxs[flav] for flav in hash_func[1:]]\n",
    "        return torch.LongTensor(flav_idxs)\n",
    "\n",
    "    def replace_flav_input(self, my_input, new_flav):\n",
    "        \"\"\"Replace existing encoding of flavor in given input, in place, with\n",
    "        encoding of 'new_flav' instead.\n",
    "        \"\"\"\n",
    "        nhot_flav_feats = len(self.flav_idxs)\n",
    "        fval = torch.tensor([self.flav_idxs[new_flav]])\n",
    "        new_flav_tensor = torch.nn.functional.one_hot(\n",
    "            fval, num_classes=nhot_flav_feats)[0]\n",
    "        my_input[0, 0, :nhot_flav_feats] = new_flav_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_vj5wPU8KtW"
   },
   "outputs": [],
   "source": [
    "class TraceLSTM(nn.Module):\n",
    "    \"\"\"Generic LSTM for flavors or duration modeling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ninput, nhidden, noutput, nlayers):\n",
    "        \"\"\"Depending on the size of the input, output, and the array of hidden\n",
    "        layers, add attributes for the inner LSTM and the\n",
    "        fully-connected layers (including both weights and a bias\n",
    "        term).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.ninput = ninput\n",
    "        self.nhidden = nhidden\n",
    "        self.noutput = noutput\n",
    "        self.nlayers = nlayers\n",
    "        self.lstm = nn.LSTM(ninput, self.nhidden, self.nlayers)\n",
    "        self.fc_out = nn.Linear(self.nhidden, noutput)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self, device=None, batch_size=1):\n",
    "        \"\"\"Before doing each new sequence, re-init hidden state to zeros.\n",
    "        \"\"\"\n",
    "        hid0 = torch.zeros(self.nlayers, batch_size, self.nhidden)\n",
    "        c_hid0 = torch.zeros(self.nlayers, batch_size, self.nhidden)\n",
    "        if device is not None:\n",
    "            hid0 = hid0.to(device)\n",
    "            c_hid0 = c_hid0.to(device)\n",
    "        return (hid0, c_hid0)\n",
    "\n",
    "    def forward(self, minibatch):\n",
    "        \"\"\"Pass in a tensor of training examples of dimension LENGTH x\n",
    "        BATCHSIZE x NINPUT, then run the forward pass. Returns tensor\n",
    "        of LENGTH x BATCHSIZE x NOUTPUT.\n",
    "        \"\"\"\n",
    "        lstm_out, self.hidden = self.lstm(minibatch, self.hidden)\n",
    "        all_logits = self.fc_out(lstm_out)\n",
    "        return all_logits\n",
    "\n",
    "    def save(self, outfn):\n",
    "        \"\"\"Use the state-dict method of saving:\n",
    "        \"\"\"\n",
    "        torch.save(self.state_dict(), outfn)\n",
    "\n",
    "    @classmethod\n",
    "    def create_from_path(cls, filename, device=None):\n",
    "        \"\"\"Factory method to return an instance of this class, given the model\n",
    "        state-dict at the current filename. If device given,\n",
    "        dynamically move model to device.\n",
    "        \"\"\"\n",
    "        if device is not None:\n",
    "            torch_device = torch.device(device)\n",
    "            state_dict = torch.load(filename, map_location=torch_device)\n",
    "        else:\n",
    "            state_dict = torch.load(filename)\n",
    "        nhidden = state_dict['fc_out.weight'].shape[1]\n",
    "        noutput = state_dict['fc_out.weight'].shape[0]\n",
    "        # LSTM layers have 4 values: ih/hh weights and ih/hh biases:\n",
    "        nlayers = len(state_dict.keys()) // 4\n",
    "        ninput = state_dict['lstm.weight_ih_l0'].shape[1]\n",
    "        new_model = cls(ninput, nhidden, noutput, nlayers)\n",
    "        new_model.load_state_dict(state_dict)\n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsNfKnkJAkxw"
   },
   "outputs": [],
   "source": [
    "class LossStats():\n",
    "    \"\"\"A class to hold, and reset as needed, the loss stats, during\n",
    "    training or testing.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize all our running totals to zero.\"\"\"\n",
    "        self.tot_loss = 0\n",
    "        self.tot_examples = 0\n",
    "\n",
    "    def update(self, num, loss):\n",
    "        \"\"\"Given we've processed num examples, and observed an average loss of\n",
    "        loss, update our totals.\n",
    "        \"\"\"\n",
    "        if num == 0:\n",
    "            return\n",
    "        self.tot_loss += loss * num\n",
    "        self.tot_examples += num\n",
    "\n",
    "    def get_tot_examples(self):\n",
    "        \"\"\"Return total number of examples processed since beginning.\"\"\"\n",
    "        return self.tot_examples\n",
    "\n",
    "    def overall_loss(self):\n",
    "        \"\"\"Calculate and return the overall loss.\"\"\"\n",
    "        return self.tot_loss / self.tot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YQqzIRb8KnT"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TrainArgs(NamedTuple):\n",
    "    \"\"\"Arguments to be used in training.\"\"\"\n",
    "    learn_rate: float\n",
    "    weight_decay: float\n",
    "    max_iters: int\n",
    "\n",
    "\n",
    "class TrainLSTM():\n",
    "    \"\"\"Class to handle flavor-LSTM training.\"\"\"\n",
    "    def __init__(self, eval_lstm, net, train_args, trainloader):\n",
    "        self.eval_lstm = eval_lstm\n",
    "        self.net = net\n",
    "        self.train_args = train_args\n",
    "        self.trainloader = trainloader\n",
    "\n",
    "    def run_train_iteration(self, data, optimizer, criterion):\n",
    "        \"\"\"Run a single training step and return the number of inputs\n",
    "        processed and the loss.\n",
    "        \"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        num, loss = self.eval_lstm.batch_forward(data, criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return num, loss\n",
    "\n",
    "    def iterate_models(self, optimizer, criterion):\n",
    "        \"\"\"Run a single training iteration and yield the loss\"\"\"\n",
    "        for epoch in range(self.train_args.max_iters):\n",
    "            self.net.train()\n",
    "            loss_stats = LossStats()\n",
    "            for iter_num, batch in enumerate(self.trainloader, 1):\n",
    "                num, loss = self.run_train_iteration(batch, optimizer,\n",
    "                                                     criterion)\n",
    "                loss_stats.update(num, loss)\n",
    "            overall_loss = loss_stats.overall_loss()\n",
    "            tot_examples = loss_stats.get_tot_examples()\n",
    "            logger.info('Train loss, epoch [%d, %7d]: %.7f',\n",
    "                        epoch, tot_examples, overall_loss)\n",
    "            yield overall_loss\n",
    "\n",
    "    def run(self, criterion):\n",
    "        \"\"\"Run training on the given neural network.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(),\n",
    "                                     lr=self.train_args.learn_rate,\n",
    "                                     weight_decay=self.train_args.weight_decay)\n",
    "        logger.info(\"Optimizer: %s\", optimizer)\n",
    "        logger.info(\"Starting training\")\n",
    "        for iter_num, train_loss in enumerate(self.iterate_models(\n",
    "                optimizer, criterion), 1):\n",
    "            self.eval_lstm.get_test_score(iter_num, criterion)\n",
    "        logger.info(\"Finished training\")\n",
    "        return self.net\n",
    "\n",
    "\n",
    "def get_init_model(args, tmaker):\n",
    "    \"\"\"Return an initial LSTM model for training, given the tensor\n",
    "    maker for this LSTM.\n",
    "    \"\"\"\n",
    "    # Get ndims from the tensor_maker for this flav_map:\n",
    "    ninput = tmaker.get_ninput()\n",
    "    noutput = tmaker.get_noutput()\n",
    "    model = TraceLSTM(ninput, args.nhidden, noutput, args.nlayers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjY2D4HXO01A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enqC-_NGzDwq"
   },
   "outputs": [],
   "source": [
    "def yield_trace_lines(trace_fn):    # trace_fn: whole dataframe\n",
    "  \"\"\"Read and yield data from the trace line-by-line: for either\n",
    "  flavors, or durations.\n",
    "  \"\"\"\n",
    "  j = 0\n",
    "  for index, row in trace_fn.iterrows():\n",
    "    hash_functs = row['HashFunction'].split(',')\n",
    "    # for index, num in enumerate(row['number_of_invocations'].split(',')):\n",
    "    #     hash_functs.insert(index+int(num)+j, '|')\n",
    "    #     j+=int(num)\n",
    "    yield row[[str(i) for i in range(1, 1441+DAYS)]].to_list(), hash_functs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JK2NRwZwxPAs"
   },
   "outputs": [],
   "source": [
    "class FlavDataset(Dataset):\n",
    "    \"\"\"A dataset that can be used for flavor sequence modeling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seq_len, dataset_fn):    # dataset_fn = line\n",
    "        \"\"\"Initialize the dataset class.\n",
    "        Args:\n",
    "        flav_map_fn: String, filename with map from flavors to their codes.\n",
    "        seq_len: Int, how long to make the sequences for each example.\n",
    "        dataset_fn: String, filename where input dataset lies.\n",
    "        range_start/stop: Int: timestamps for start/end of training data.\n",
    "        \"\"\"\n",
    "        self.seq_len = seq_len\n",
    "        self.tmaker = FlavTensorMaker(hash_functions)   # takes hashes of functions\n",
    "        trace_data = yield_trace_lines(dataset_fn)  # takkes whole dataset\n",
    "        # make one giant example, getitem() & len() will take pieces:\n",
    "        self.all_inputs, self.all_targets = self.__make_example_tensor(\n",
    "            trace_data)\n",
    "        \n",
    "        assert len(self.all_inputs) == len(self.all_targets)\n",
    "\n",
    "    def __make_example_tensor(self, trace_data):    # trace_data = whole dataset\n",
    "        \"\"\"Go through lines in trace and create one big example tensor, where\n",
    "        the first dimension is example number.\n",
    "        \"\"\"\n",
    "        all_inputs, all_targets = [], []\n",
    "        for idx, line in enumerate(trace_data):\n",
    "            my_input, my_target = self.__make_example_from_line(line)\n",
    "            all_inputs.append(my_input)\n",
    "            all_targets.append(my_target)\n",
    "            if idx > 1 and idx % REPORT == 0:\n",
    "                logger.info(\"Read %s dataset lines\", idx)\n",
    "        logger.info(\"Read %s dataset lines\", idx)\n",
    "        # Create a single vector for each of these by reshaping:\n",
    "        all_inputs = torch.cat(all_inputs)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "        all_inputs, all_targets = self.__reshape_data(\n",
    "            all_inputs, all_targets)\n",
    "        return all_inputs, all_targets\n",
    "\n",
    "    def __reshape_data(self, all_inputs, all_targets):\n",
    "        \"\"\"Depending on the sequence length, reshape accordingly.  Also, pad\n",
    "         with targets with IGNORE_INDEX so that we divide evenly.\n",
    "        \"\"\"\n",
    "        nflavs = len(all_inputs)\n",
    "        nseqs = ceil(1.0 * nflavs / self.seq_len)\n",
    "        padding_needed = nseqs * self.seq_len - nflavs\n",
    "        fake_targets = (torch.ones(padding_needed, dtype=torch.long) *\n",
    "                        IGNORE_INDEX)\n",
    "        all_targets = torch.cat([all_targets, fake_targets])\n",
    "        fake_input_shape = list(all_inputs.shape)\n",
    "        fake_input_shape[0] = padding_needed\n",
    "        fake_input = torch.zeros(fake_input_shape)\n",
    "        all_inputs = torch.cat([all_inputs, fake_input])\n",
    "        # After padding, reshape into sequences of seq_len:\n",
    "        reshaped_inputs = all_inputs.reshape(-1, self.seq_len, 1,\n",
    "                                             fake_input_shape[-1])\n",
    "        reshaped_targets = all_targets.reshape(-1, self.seq_len)\n",
    "        return reshaped_inputs, reshaped_targets\n",
    "\n",
    "    def __make_example_from_line(self, line):\n",
    "        \"\"\"Unpack the line and make the example from it.\n",
    "        \"\"\"\n",
    "        timestamp, flavs = line\n",
    "        # timestamp = int(timestamp)\n",
    "        # Lines don't BEGIN with BOUND, so put it on:\n",
    "        flavs = [BOUND] + flavs\n",
    "        ex_input = self.tmaker.encode_input(timestamp, flavs)\n",
    "        ex_target = self.tmaker.encode_target(flavs)\n",
    "        return ex_input, ex_target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of sequences of length seq_len:\n",
    "        \"\"\"\n",
    "        return len(self.all_targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return an example from all our pre-made tensors.\"\"\"\n",
    "        ex_input = self.all_inputs[idx]\n",
    "        ex_target = self.all_targets[idx]\n",
    "        sample = {ExampleKeys.INPUT: ex_input,\n",
    "                  ExampleKeys.TARGET: ex_target}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxS1lvmXRY40"
   },
   "outputs": [],
   "source": [
    "class CollateUtils():\n",
    "    \"\"\"Utility collate functions for the DataLoaders.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def batching_collator(batch):\n",
    "        \"\"\"Return an example (dict) where the values are now minibatches.\n",
    "        Arguments: batch: an iterable over example (dicts) in a Dataset\n",
    "        Returns: collated, a single example with minibatch payload\n",
    "        \"\"\"\n",
    "        all_inputs = []\n",
    "        all_targets = []\n",
    "        all_masks = []\n",
    "        do_masks = batch[0].get(ExampleKeys.OUT_MASK) is not None\n",
    "        for example in batch:\n",
    "            all_inputs.append(example[ExampleKeys.INPUT])\n",
    "            # targets are either a flat SEQ_LEN vector of targets (in\n",
    "            # flavors) or 47 (in durs), so reshape accordingly:\n",
    "            targets = example[ExampleKeys.TARGET]\n",
    "            if len(targets.shape) == 1:\n",
    "                all_targets.append(targets.reshape(-1, 1, 1))\n",
    "            else:\n",
    "                all_targets.append(targets.reshape(-1, 1, targets.shape[-1]))\n",
    "            if do_masks:\n",
    "                masks = example[ExampleKeys.OUT_MASK]\n",
    "                all_masks.append(masks.reshape(-1, 1, targets.shape[-1]))\n",
    "        # Join them together along the batch dimension:\n",
    "        new_inputs = torch.cat(all_inputs, dim=1)\n",
    "        new_targets = torch.cat(all_targets, dim=1)\n",
    "        collated = {ExampleKeys.INPUT: new_inputs,\n",
    "                    ExampleKeys.TARGET: new_targets}\n",
    "        if do_masks:\n",
    "            new_masks = torch.cat(all_masks, dim=1)\n",
    "            collated[ExampleKeys.OUT_MASK] = new_masks\n",
    "        return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mElv4CkfYpSJ"
   },
   "outputs": [],
   "source": [
    "class Evaluator(ABC):\n",
    "    \"\"\"Class to run the forward pass and compute test scores.\"\"\"\n",
    "    def __init__(self, net, device_str, testloader):\n",
    "        self.net = net\n",
    "        self.device = torch.device(device_str)\n",
    "        self.testloader = testloader\n",
    "        if self.device.type == \"cuda\":\n",
    "            if self.device.index == 0:\n",
    "                self.net = self.net.cuda(0)\n",
    "            else:\n",
    "                self.net = self.net.cuda(1)\n",
    "\n",
    "    @abstractmethod\n",
    "    def batch_forward(self, batch, criterion):\n",
    "        \"\"\"Override to pick the outputs for the batch, compute the loss.\"\"\"\n",
    "\n",
    "    def get_test_score(self, epoch, criterion):\n",
    "        \"\"\"Get the score of current net on test set.\"\"\"\n",
    "        loss_stats = LossStats()\n",
    "        with torch.no_grad():\n",
    "            self.net.eval()\n",
    "            for iter_num, batch in enumerate(self.testloader, 1):\n",
    "                num, loss = self.batch_forward(batch, criterion)\n",
    "                loss_stats.update(num, loss)\n",
    "        overall_loss = loss_stats.overall_loss()\n",
    "        if epoch is not None:\n",
    "            logger.info('Test loss, epoch [%d]: %.7f', epoch, overall_loss)\n",
    "        else:\n",
    "            logger.info('Test loss: %.7f', overall_loss)\n",
    "        return overall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFANJLAFFZWw"
   },
   "outputs": [],
   "source": [
    "def make_flav_dataloaders(args):\n",
    "\n",
    "    try:\n",
    "        trainset = FlavDataset(args.seq_len, args.train_flavs)\n",
    "        trainloader = DataLoader(trainset, batch_size=args.batch_size,\n",
    "                                 collate_fn=CollateUtils.batching_collator,\n",
    "                                 shuffle=True)\n",
    "        \n",
    "    except AttributeError:\n",
    "        # No train_flavs provided:\n",
    "        trainloader = None\n",
    "    testset = FlavDataset(args.seq_len, args.test_flavs)\n",
    "    testloader = DataLoader(testset, batch_size=args.batch_size,\n",
    "                            collate_fn=CollateUtils.batching_collator,\n",
    "                            shuffle=False)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "class EvaluateFlavLSTM(Evaluator):\n",
    "    \"\"\"Class to help with testing of a flavor LSTM.\"\"\"\n",
    "    def batch_forward(self, batch, criterion):\n",
    "        \"\"\"Run the forward pass and get the number of examples and the loss.\n",
    "        \"\"\"\n",
    "        inputs = batch[ExampleKeys.INPUT]\n",
    "        targets = batch[ExampleKeys.TARGET]\n",
    "        num = targets[targets != IGNORE_INDEX].numel()\n",
    "        inputs, targets = (inputs.to(self.device),\n",
    "                           targets.to(self.device))\n",
    "        batch_size = inputs.shape[1]\n",
    "        self.net.hidden = self.net.init_hidden(self.device, batch_size)\n",
    "        outputs = self.net(inputs)\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        targets = targets.reshape(-1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        return num, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuBjlZK1EivD"
   },
   "source": [
    "# Flav Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CIsHaPkcl3R"
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, [str(i) for i in range(1, 1441+DAYS)] + ['HashFunction']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKQTBUO1Gxb8"
   },
   "outputs": [],
   "source": [
    "args={\n",
    "    \"train_flavs\" : X_train,\n",
    "    \"test_flavs\" : X_test,\n",
    "    \"device\" : \"cuda:0\" , \n",
    "    \"seq_len\" : 500,\n",
    "    \"batch_size\" : 100,\n",
    "    \"range_start\" : 0,\n",
    "    \"max_iters\" : 10,\n",
    "    \"lr\" : 5e-3,\n",
    "    \"weight_decay\" : 1e-5, \n",
    "    \"nlayers\" : 2,\n",
    "    \"nhidden\" :  200,\n",
    "    \"model_save_fn\" : data_path + 'func_model.pth'\n",
    "}\n",
    "\n",
    "# Convert Dict to object\n",
    "args = namedtuple(\"Args\", args.keys())(*args.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kXIMP6mbBJW",
    "outputId": "5b147728-eb6c-4f57-c512-31d652ea8ccb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8skQb97_EieW",
    "outputId": "bbe4a2fe-acd3-438a-ceef-5aeceb563095"
   },
   "outputs": [],
   "source": [
    "tmaker = FlavTensorMaker(hash_functions)\n",
    "net = get_init_model(args, tmaker)\n",
    "trainloader, testloader = make_flav_dataloaders(args)\n",
    "train_args = TrainArgs(args.lr, args.weight_decay, args.max_iters)\n",
    "eval_lstm = EvaluateFlavLSTM(net, args.device, testloader)\n",
    "train_run = TrainLSTM(eval_lstm, net, train_args, trainloader)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "trained_net = train_run.run(criterion)\n",
    "\n",
    "torch.save(trained_net, args.model_save_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOcg5n4aDstJ",
    "outputId": "ec03fc0c-d269-479b-f195-ade41faefffc"
   },
   "outputs": [],
   "source": [
    " X_test[[str(i) for i in range(1, 1441+DAYS)]].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGgeTi413Bvy"
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-ET2gBcyDnJ"
   },
   "outputs": [],
   "source": [
    "args={\n",
    "    \"arrival_model_pkl\" : data_path + \"arr_model.pkl\",\n",
    "    \"device\" : \"cpu\" ,\n",
    "    \"flav_model\" : data_path + \"func_model.pth\",\n",
    "    \"out_flavs_fn\" : \"tmp.flavs\",\n",
    "    \"minute_day\": X_test[[str(i) for i in range(1, 1441+DAYS)]].to_numpy()\n",
    "}\n",
    "\n",
    "# Convert Dict to object\n",
    "args = namedtuple(\"Args\", args.keys())(*args.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL2x25qg3Ely"
   },
   "outputs": [],
   "source": [
    "class GenLSTM():\n",
    "    \"\"\"An evaluator that only does forward pass (no loss calculation).\"\"\"\n",
    "    def __init__(self, net, device):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "\n",
    "    def init_hidden(self):\n",
    "        self.net.hidden = self.net.init_hidden(self.device)\n",
    "\n",
    "    def forward(self, my_input):\n",
    "        outputs = self.net(my_input)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-2asHoyAISN"
   },
   "outputs": [],
   "source": [
    "def make_arrival_vector(x):\n",
    "    return x\n",
    "\n",
    "def encode_trace_line(timestamp, item_lst):\n",
    "    itemstr = ITEM_DATA_SEP.join(item_lst)\n",
    "    out_str = \"{}{}{}\".format(timestamp, TRACE_DATA_SEP, itemstr)\n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIwSyHN83Gjq"
   },
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    \"\"\"Creates an object that generates a trace (flavs and durs) according\n",
    "    to our batching baseline trace generator process.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, arrival_mdl, flav_lstm):\n",
    "        \"\"\"arrival_mdl: the Poisson GLM mdl from statsmodels\n",
    "        flav_lstm/dur_lstm: LSTM evaluators to run forward passes\n",
    "        flav_map_fn: String, filename with map from flavors to their codes.\n",
    "        interval_map_fn: String, filename where mapping from durations\n",
    "        to intervals stored. Used here to get list of intervals.\n",
    "        bsize_map_fn: String, mapping from integers to bsize codes\n",
    "        (e.g. 11-15, or 26-50).  This is batches of flavors, not to be\n",
    "        confused with \"batches\" of examples for ML.\n",
    "        range_start/stop: Int: timestamps for start/end of training data.\n",
    "        range_idx: Int: If given, tensor maker will use this index in\n",
    "        the range features (modulo the number of range features).\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.arrival_mdl = arrival_mdl\n",
    "        self.flav_to_idxs, self.idx_to_flavs = FlavTensorMaker.get_flav_idxs(hash_functions)\n",
    "        \n",
    "        self.flav_tmaker = FlavTensorMaker(hash_functions)\n",
    "        \n",
    "        self.flav_lstm = flav_lstm\n",
    "\n",
    "    def __get_narrivals(self, timestamp):\n",
    "        pred_mean = self.arrival_mdl.predict([timestamp])[0]\n",
    "        narrivals = np.random.poisson(pred_mean)\n",
    "        return narrivals\n",
    "\n",
    "    def __init_flav_input(self, timestamp):\n",
    "        \"\"\"Initialize input tensor to a BOUND at given timestamp.\"\"\"\n",
    "        flav_lst = [BOUND, BOUND]  # second BOUND ignored by tmaker\n",
    "        my_input = self.flav_tmaker.encode_input(timestamp, flav_lst)\n",
    "        my_input = my_input.to(self.device)\n",
    "        return my_input\n",
    "\n",
    "    def __adjust_flav_input(self, my_input, prev_flav):\n",
    "        \"\"\"Replace the flavor part of the input only.\"\"\"\n",
    "        self.flav_tmaker.replace_flav_input(my_input, prev_flav)\n",
    "        return my_input\n",
    "\n",
    "    def __sample_flav(self, output):\n",
    "        \"\"\"Sample flavor from output of flavor LSTM.\"\"\"\n",
    "        probs = torch.softmax(output.reshape(-1), dim=0)\n",
    "        flav_idx = torch.multinomial(probs, 1).item()\n",
    "        # Also get flavor string itself:\n",
    "        flav_flav = self.idx_to_flavs[flav_idx]\n",
    "        return flav_flav, flav_idx\n",
    "\n",
    "    def __generate_flavs(self, timestamp, target_nbatches):\n",
    "        \"\"\"Auto-regressively generate target_nbatches batches of flavors, at\n",
    "        given timestamp.\n",
    "        \"\"\"\n",
    "        my_input = self.__init_flav_input(timestamp)\n",
    "        flav_flavs = []\n",
    "        flav_idxs = []\n",
    "        nseen_batches = 0\n",
    "        prev_flav = BOUND\n",
    "        while True:\n",
    "            output = self.flav_lstm.forward(my_input)\n",
    "            next_flav, next_idx = self.__sample_flav(output)\n",
    "            # Shouldn't happen, but skip if it does:\n",
    "            if next_flav == BOUND and prev_flav == BOUND:\n",
    "                continue\n",
    "            flav_flavs.append(next_flav)\n",
    "            flav_idxs.append(next_idx)\n",
    "            # Increment number batches seen on each bound:\n",
    "            if next_flav == BOUND:\n",
    "                nseen_batches += 1\n",
    "                if nseen_batches == target_nbatches:\n",
    "                    break\n",
    "            # Otherwise, get next input and continue:\n",
    "            my_input = self.__adjust_flav_input(my_input, next_flav)\n",
    "            prev_flav = next_flav\n",
    "        return flav_flavs, flav_idxs\n",
    "\n",
    "\n",
    "    def __generate_batches(self, timestamp, nbatches):\n",
    "        \"\"\"Use flav/dur LSTMs to generate trace for a single row/timestamp.\"\"\"\n",
    "        flav_flavs, flav_idxs = self.__generate_flavs(timestamp, nbatches)\n",
    "        return flav_idxs\n",
    "\n",
    "    def __output_flavs(self, timestamp, flav_idxs, out_flavs_file):\n",
    "        \"\"\"Make and output the flavor line.\"\"\"\n",
    "        flav_lst = [self.idx_to_flavs[i] for i in flav_idxs]\n",
    "        flav_out = encode_trace_line(timestamp, flav_lst)\n",
    "        print(flav_out, file=out_flavs_file)\n",
    "\n",
    "    def __output_zero_arrivals(self, timestamp, out_flavs_file):\n",
    "        flav_out = encode_trace_line(timestamp, [])\n",
    "        print(flav_out, file=out_flavs_file)\n",
    "\n",
    "\n",
    "    def __call__(self, out_flavs_file):\n",
    "        \"\"\"Generate trace for timestamps from start_s to stop_s inclusive.\"\"\"\n",
    "        self.flav_lstm.init_hidden()\n",
    "        for ntimestamps, timestamp in enumerate(args.minute_day):\n",
    "            nbatches = self.__get_narrivals(timestamp)\n",
    "            if nbatches == 0:\n",
    "                self.__output_zero_arrivals(timestamp, out_flavs_file)\n",
    "                continue\n",
    "            flav_idxs = self.__generate_batches(timestamp, nbatches)\n",
    "            self.__output_flavs(timestamp, flav_idxs, out_flavs_file)\n",
    "            if ntimestamps > 0 and ntimestamps % REPORT == 0:\n",
    "                logger.info(\"Generated %d output lines (now on %d)\", ntimestamps, timestamp)\n",
    "\n",
    "\n",
    "def get_lstm_eval(device, model_fn):\n",
    "    \"\"\"Initialize the generation LSTM evaluator.\"\"\"\n",
    "    net = trained_net # TraceLSTM.create_from_path(model_fn, device)\n",
    "    return GenLSTM(net, device)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    logger.info(\"Reading models\")\n",
    "    arrival_mdl = sm.load(args.arrival_model_pkl)\n",
    "    flav_gen = get_lstm_eval(args.device, args.flav_model)\n",
    "    lstm_generator = Generator(args.device, arrival_mdl, flav_gen)\n",
    "    with open(args.out_flavs_fn, \"w\") as flavs_file:\n",
    "        logger.info(\"Running generation\")\n",
    "        lstm_generator(flavs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0l6epTG_AMA"
   },
   "outputs": [],
   "source": [
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Generation of Workload for FaaS : case of Microsoft Azure .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
